{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-de61977f3e5a3574\n",
      "Reusing dataset json (/home/v-yichengzou/.cache/huggingface/datasets/json/default-de61977f3e5a3574/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a44a3e3c6edf48618da192019cee7570",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['topic_list', 'general_query_list', 'specific_query_list', 'meeting_transcripts'],\n",
      "        num_rows: 162\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['topic_list', 'general_query_list', 'specific_query_list', 'meeting_transcripts'],\n",
      "        num_rows: 35\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['topic_list', 'general_query_list', 'specific_query_list', 'meeting_transcripts'],\n",
      "        num_rows: 35\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31dd34ccdcc442a0ab89e952ac39e89a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running process on dataset:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb0efe511eec4c589a9ae360aa692074",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running process on dataset:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "401ff71c55874b8eaa702e05efb70d68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running process on dataset:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['dialogue', 'summary', 'id'],\n",
      "        num_rows: 1095\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['dialogue', 'summary', 'id'],\n",
      "        num_rows: 237\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['dialogue', 'summary', 'id'],\n",
      "        num_rows: 244\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# QMSum\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\n",
    "    'json',\n",
    "    data_files={\n",
    "        'train': ['data/qmsum/raw_data/train.jsonl'],\n",
    "        'validation': ['data/qmsum/raw_data/val.jsonl'],\n",
    "        'test': ['data/qmsum/raw_data/test.jsonl']\n",
    "    }\n",
    ")\n",
    "print(dataset)\n",
    "\n",
    "def process(exs):\n",
    "    dialogues = []\n",
    "    summaries = []\n",
    "    ids = []\n",
    "    query_list = exs['specific_query_list']\n",
    "    meetings = exs['meeting_transcripts']\n",
    "    for i, meeting in enumerate(meetings):\n",
    "        meeting = list(map(lambda x: x['speaker'] + \": \" + x['content'], meeting))\n",
    "        for j, pair in enumerate(query_list[i]):\n",
    "            query = pair['query']\n",
    "            summary = pair['answer']\n",
    "            context = \"\\r\\n\".join(['\\r\\n'.join(meeting[int(st):int(ed)+1]) for st, ed in pair['relevant_text_span']])\n",
    "            dialogue = query + ' ##\\r\\n' + context\n",
    "            dialogues.append(dialogue)\n",
    "            summaries.append(summary)\n",
    "            ids.append(str(i)+'_'+str(j))\n",
    "    return {\n",
    "        \"dialogue\": dialogues,\n",
    "        \"summary\": summaries,\n",
    "        \"id\": ids\n",
    "    }\n",
    "processed_dataset = dataset.map(\n",
    "    process,\n",
    "    batched=True,\n",
    "    num_proc=1,\n",
    "    remove_columns=dataset[\"train\"].column_names,\n",
    "    load_from_cache_file=False,\n",
    "    desc=\"Running process on dataset\",\n",
    ")\n",
    "\n",
    "processed_dataset.save_to_disk('data/qmsum/qmsum')\n",
    "print(processed_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-00a44acd03064a31\n",
      "Reusing dataset json (/home/v-yichengzou/.cache/huggingface/datasets/json/default-00a44acd03064a31/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b)\n",
      "Using custom data configuration default-c4407731ccbc3b5b\n",
      "Reusing dataset json (/home/v-yichengzou/.cache/huggingface/datasets/json/default-c4407731ccbc3b5b/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b)\n",
      "Using custom data configuration default-a4e55bb77cf59c64\n",
      "Reusing dataset json (/home/v-yichengzou/.cache/huggingface/datasets/json/default-a4e55bb77cf59c64/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['fname', 'dialogue', 'summary', 'topic'],\n",
      "        num_rows: 12460\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['fname', 'dialogue', 'summary', 'topic'],\n",
      "        num_rows: 500\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['fname', 'dialogue', 'summary1', 'topic1', 'summary2', 'topic2', 'summary3', 'topic3'],\n",
      "        num_rows: 500\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec62c4c9ceca47ea8fe44e52288bd63f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running process on dataset:   0%|          | 0/13 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a61712e1c16f4e56836f7ae40dfa4790",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running process on dataset:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abe43ef11c97454d9b4788bfad2e8b8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running process on dataset:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['dialogue', 'summary', 'id'],\n",
      "        num_rows: 12460\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['dialogue', 'summary', 'id'],\n",
      "        num_rows: 500\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['dialogue', 'summary', 'id'],\n",
      "        num_rows: 500\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# dialsumm\n",
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "dataset = DatasetDict({\n",
    "    \"train\": load_dataset('json', data_files='data/dialsumm/raw_data/dialogsum.train.jsonl', split='train'),\n",
    "    \"validation\": load_dataset('json', data_files='data/dialsumm/raw_data/dialogsum.dev.jsonl', split='train'),\n",
    "    \"test\": load_dataset('json', data_files='data/dialsumm/raw_data/dialogsum.test.jsonl', split='train')\n",
    "})\n",
    "\n",
    "print(dataset)\n",
    "\n",
    "def process(exs):\n",
    "    summaries = []\n",
    "    if \"summary1\" in exs:\n",
    "        for s1, s2, s3 in zip(exs['summary1'], exs['summary2'], exs['summary3']):\n",
    "            s = s1\n",
    "            if len(s1) < len(s2):\n",
    "                s = s2\n",
    "            if len(s2) < len(s3):\n",
    "                s = s3\n",
    "            summaries.append(s)\n",
    "    return {\n",
    "        \"dialogue\": exs['dialogue'],\n",
    "        \"summary\": exs['summary'] if \"summary1\" not in exs else summaries,\n",
    "        \"id\": exs['fname']\n",
    "    }\n",
    "process_train = dataset['train'].map(\n",
    "    process,\n",
    "    batched=True,\n",
    "    num_proc=1,\n",
    "    remove_columns=dataset['train'].column_names,\n",
    "    load_from_cache_file=False,\n",
    "    desc=\"Running process on dataset\",\n",
    ")\n",
    "process_dev = dataset['validation'].map(\n",
    "    process,\n",
    "    batched=True,\n",
    "    num_proc=1,\n",
    "    remove_columns=dataset['validation'].column_names,\n",
    "    load_from_cache_file=False,\n",
    "    desc=\"Running process on dataset\",\n",
    ")\n",
    "process_test = dataset['test'].map(\n",
    "    process,\n",
    "    batched=True,\n",
    "    num_proc=1,\n",
    "    remove_columns=dataset['test'].column_names,\n",
    "    load_from_cache_file=False,\n",
    "    desc=\"Running process on dataset\",\n",
    ")\n",
    "processed_dataset = DatasetDict({\n",
    "    \"train\": process_train,\n",
    "    \"validation\": process_dev,\n",
    "    \"test\": process_test\n",
    "})\n",
    "processed_dataset.save_to_disk('data/dialsumm/dialsumm')\n",
    "print(processed_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-b0aa02ed7e9cb25a\n",
      "Reusing dataset json (/home/v-yichengzou/.cache/huggingface/datasets/json/default-b0aa02ed7e9cb25a/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b)\n",
      "Using custom data configuration default-c89997efc37619e6\n",
      "Reusing dataset json (/home/v-yichengzou/.cache/huggingface/datasets/json/default-c89997efc37619e6/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b)\n",
      "Using custom data configuration default-e9ed5e55bfc11921\n",
      "Reusing dataset json (/home/v-yichengzou/.cache/huggingface/datasets/json/default-e9ed5e55bfc11921/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b)\n",
      "Using custom data configuration default-f290029cf0075597\n",
      "Reusing dataset json (/home/v-yichengzou/.cache/huggingface/datasets/json/default-f290029cf0075597/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b)\n",
      "Using custom data configuration default-32c81f4204f23a49\n",
      "Reusing dataset json (/home/v-yichengzou/.cache/huggingface/datasets/json/default-32c81f4204f23a49/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b)\n",
      "Using custom data configuration default-dc8883ee46c186bd\n",
      "Reusing dataset json (/home/v-yichengzou/.cache/huggingface/datasets/json/default-dc8883ee46c186bd/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['Recap', 'Transcript', 'filename'],\n",
      "        num_rows: 22588\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['Recap', 'Transcript', 'filename'],\n",
      "        num_rows: 2133\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['Recap', 'Transcript', 'filename'],\n",
      "        num_rows: 2130\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64aeffa7dc63418097576322a5e51bc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running process on dataset:   0%|          | 0/23 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3426455dc1214bb9a26d5307f345d01a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running process on dataset:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05df473b404041e9ab7211e281826049",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running process on dataset:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['dialogue', 'summary', 'id'],\n",
      "        num_rows: 22588\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['dialogue', 'summary', 'id'],\n",
      "        num_rows: 2133\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['dialogue', 'summary', 'id'],\n",
      "        num_rows: 2130\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# summscreen\n",
    "from datasets import load_dataset, DatasetDict, concatenate_datasets\n",
    "\n",
    "dataset = DatasetDict({\n",
    "    \"train\": concatenate_datasets([\n",
    "        load_dataset('json', data_files='data/summscreen/raw_data/ForeverDreaming/fd_train.json', split='train'),\n",
    "        load_dataset('json', data_files='data/summscreen/raw_data/TVMegaSite/tms_train.json', split='train'),\n",
    "    ]),\n",
    "    \"validation\": concatenate_datasets([\n",
    "        load_dataset('json', data_files='data/summscreen/raw_data/ForeverDreaming/fd_dev.json', split='train'),\n",
    "        load_dataset('json', data_files='data/summscreen/raw_data/TVMegaSite/tms_dev.json', split='train'),\n",
    "    ]),\n",
    "    \"test\": concatenate_datasets([\n",
    "        load_dataset('json', data_files='data/summscreen/raw_data/ForeverDreaming/fd_test.json', split='train'),\n",
    "        load_dataset('json', data_files='data/summscreen/raw_data/TVMegaSite/tms_test.json', split='train'),\n",
    "    ])\n",
    "})\n",
    "\n",
    "print(dataset)\n",
    "\n",
    "def process(exs):\n",
    "    dialogues = []\n",
    "    summaries = []\n",
    "    for d in exs['Transcript']:\n",
    "        newd = \"\\r\\n\".join([s.replace(\"@@ \", \"\").replace(\" '\", \"'\") for s in d])\n",
    "        dialogues.append(newd)\n",
    "    for d in exs['Recap']:\n",
    "        newd = \" \".join([s.replace(\"@@ \", \"\").replace(\" '\", \"'\") for s in d])\n",
    "        summaries.append(newd)\n",
    "    return {\n",
    "        \"dialogue\": dialogues,\n",
    "        \"summary\": summaries,\n",
    "        \"id\": exs['filename']\n",
    "    }\n",
    "processed_dataset = dataset.map(\n",
    "    process,\n",
    "    batched=True,\n",
    "    num_proc=1,\n",
    "    remove_columns=dataset['train'].column_names,\n",
    "    load_from_cache_file=False,\n",
    "    desc=\"Running process on dataset\",\n",
    ")\n",
    "processed_dataset.save_to_disk('data/summscreen/summscreen')\n",
    "print(processed_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['dialogue', 'summary'],\n",
      "        num_rows: 879\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['dialogue', 'summary'],\n",
      "        num_rows: 110\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['dialogue', 'summary'],\n",
      "        num_rows: 110\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e30c83495344351a81611ba88995c94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running process on dataset:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2a95217fb5841a6be3c601e3abfbb47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running process on dataset:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "947e6b9db6864d8cb17558534de437c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running process on dataset:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['dialogue', 'summary', 'id'],\n",
      "        num_rows: 879\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['dialogue', 'summary', 'id'],\n",
      "        num_rows: 110\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['dialogue', 'summary', 'id'],\n",
      "        num_rows: 110\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# tweetsumm\n",
    "import json\n",
    "from datasets import Dataset, DatasetDict, concatenate_datasets\n",
    "from data.tweetsumm.raw_data.Tweetsumm.tweet_sum_processor import TweetSumProcessor\n",
    "\n",
    "processor = TweetSumProcessor(\"/home/v-yichengzou/projects/summ/data/tweetsumm/raw_data/twcs/twcs.csv\")\n",
    "test_set = {\"dialogue\": [], \"summary\": []}\n",
    "with open(\"/home/v-yichengzou/projects/summ/data/tweetsumm/raw_data/Tweetsumm/tweet_sum_data_files/final_test_tweetsum.jsonl\") as f:\n",
    "    dialog_with_summaries = processor.get_dialog_with_summaries(f.readlines())\n",
    "    for dialog_with_summary in dialog_with_summaries:\n",
    "        json_format = dialog_with_summary.get_json()\n",
    "        json_data = json.loads(json_format)\n",
    "        test_set['dialogue'].append(json_data['dialog'])\n",
    "        test_set['summary'].append(json_data['summaries']['abstractive_summaries'])\n",
    "\n",
    "eval_set = {\"dialogue\": [], \"summary\": []}\n",
    "with open(\"/home/v-yichengzou/projects/summ/data/tweetsumm/raw_data/Tweetsumm/tweet_sum_data_files/final_valid_tweetsum.jsonl\") as f:\n",
    "    dialog_with_summaries = processor.get_dialog_with_summaries(f.readlines())\n",
    "    for dialog_with_summary in dialog_with_summaries:\n",
    "        json_format = dialog_with_summary.get_json()\n",
    "        json_data = json.loads(json_format)\n",
    "        eval_set['dialogue'].append(json_data['dialog'])\n",
    "        eval_set['summary'].append(json_data['summaries']['abstractive_summaries'])\n",
    "\n",
    "train_set = {\"dialogue\": [], \"summary\": []}\n",
    "with open(\"/home/v-yichengzou/projects/summ/data/tweetsumm/raw_data/Tweetsumm/tweet_sum_data_files/final_train_tweetsum.jsonl\") as f:\n",
    "    dialog_with_summaries = processor.get_dialog_with_summaries(f.readlines())\n",
    "    for dialog_with_summary in dialog_with_summaries:\n",
    "        json_format = dialog_with_summary.get_json()\n",
    "        json_data = json.loads(json_format)\n",
    "        train_set['dialogue'].append(json_data['dialog'])\n",
    "        train_set['summary'].append(json_data['summaries']['abstractive_summaries'])\n",
    "\n",
    "dataset = DatasetDict({\n",
    "    \"train\": Dataset.from_dict(train_set),\n",
    "    \"validation\": Dataset.from_dict(eval_set),\n",
    "    \"test\": Dataset.from_dict(test_set)\n",
    "})\n",
    "\n",
    "print(dataset)\n",
    "\n",
    "def process(exs):\n",
    "    dialogues = []\n",
    "    summaries = []\n",
    "    ids = []\n",
    "    for d in exs['dialogue']:\n",
    "        ids.append(d['dialog_id'])\n",
    "        newd = \"\\r\\n\".join([' '.join(s['sentences']) for s in d['turns']])\n",
    "        dialogues.append(newd)\n",
    "    for summary in exs['summary']:\n",
    "        best_s, len_s = \"\", 0\n",
    "        for s in summary:\n",
    "            news = \" \".join(s)\n",
    "            if len(news) > len_s:\n",
    "                best_s, len_s = news, len(news)\n",
    "        summaries.append(best_s)\n",
    "    return {\n",
    "        \"dialogue\": dialogues,\n",
    "        \"summary\": summaries,\n",
    "        \"id\": ids\n",
    "    }\n",
    "processed_dataset = dataset.map(\n",
    "    process,\n",
    "    batched=True,\n",
    "    num_proc=1,\n",
    "    remove_columns=dataset['train'].column_names,\n",
    "    load_from_cache_file=False,\n",
    "    desc=\"Running process on dataset\",\n",
    ")\n",
    "processed_dataset.save_to_disk('data/tweetsumm/tweetsumm')\n",
    "print(processed_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['dialogue', 'summary', 'id'],\n",
      "        num_rows: 1800\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['dialogue', 'summary', 'id'],\n",
      "        num_rows: 249\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['dialogue', 'summary', 'id'],\n",
      "        num_rows: 500\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# emailsum\n",
    "import json\n",
    "from datasets import Dataset, DatasetDict, concatenate_datasets\n",
    "\n",
    "train_set = {\"dialogue\": [], \"summary\": [], \"id\": []}\n",
    "with open(\"data/emailsum/raw_data/avocado/data_email_long/train.source.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        train_set['dialogue'].append(line.replace(\"|||\", '\\r\\n'))\n",
    "with open(\"data/emailsum/raw_data/avocado/data_email_long/train.target.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        train_set['summary'].append(line)\n",
    "with open(\"data/emailsum/raw_data/avocado/data_email_long/train.id.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        train_set['id'].append(line)\n",
    "\n",
    "eval_set = {\"dialogue\": [], \"summary\": [], \"id\": []}\n",
    "with open(\"data/emailsum/raw_data/avocado/data_email_long/dev.source.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        eval_set['dialogue'].append(line.replace(\"|||\", '\\r\\n'))\n",
    "with open(\"data/emailsum/raw_data/avocado/data_email_long/dev.target.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        eval_set['summary'].append(line)\n",
    "with open(\"data/emailsum/raw_data/avocado/data_email_long/dev.id.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        eval_set['id'].append(line)\n",
    "\n",
    "test_set = {\"dialogue\": [], \"summary\": [], \"id\": []}\n",
    "with open(\"data/emailsum/raw_data/avocado/data_email_long/test.source.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        test_set['dialogue'].append(line.replace(\"|||\", '\\r\\n'))\n",
    "with open(\"data/emailsum/raw_data/avocado/data_email_long/test.target.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        test_set['summary'].append(line)\n",
    "with open(\"data/emailsum/raw_data/avocado/data_email_long/test.id.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        test_set['id'].append(line)\n",
    "\n",
    "dataset = DatasetDict({\n",
    "    \"train\": Dataset.from_dict(train_set),\n",
    "    \"validation\": Dataset.from_dict(eval_set),\n",
    "    \"test\": Dataset.from_dict(test_set)\n",
    "})\n",
    "\n",
    "dataset.save_to_disk('data/emailsum/emailsum_long')\n",
    "\n",
    "train_set = {\"dialogue\": [], \"summary\": [], \"id\": []}\n",
    "with open(\"data/emailsum/raw_data/avocado/data_email_short/train.source.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        train_set['dialogue'].append(line.replace(\"|||\", '\\r\\n'))\n",
    "with open(\"data/emailsum/raw_data/avocado/data_email_short/train.target.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        train_set['summary'].append(line)\n",
    "with open(\"data/emailsum/raw_data/avocado/data_email_short/train.id.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        train_set['id'].append(line)\n",
    "\n",
    "eval_set = {\"dialogue\": [], \"summary\": [], \"id\": []}\n",
    "with open(\"data/emailsum/raw_data/avocado/data_email_short/dev.source.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        eval_set['dialogue'].append(line.replace(\"|||\", '\\r\\n'))\n",
    "with open(\"data/emailsum/raw_data/avocado/data_email_short/dev.target.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        eval_set['summary'].append(line)\n",
    "with open(\"data/emailsum/raw_data/avocado/data_email_short/dev.id.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        eval_set['id'].append(line)\n",
    "\n",
    "test_set = {\"dialogue\": [], \"summary\": [], \"id\": []}\n",
    "with open(\"data/emailsum/raw_data/avocado/data_email_short/test.source.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        test_set['dialogue'].append(line.replace(\"|||\", '\\r\\n'))\n",
    "with open(\"data/emailsum/raw_data/avocado/data_email_short/test.target.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        test_set['summary'].append(line)\n",
    "with open(\"data/emailsum/raw_data/avocado/data_email_short/test.id.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        test_set['id'].append(line)\n",
    "\n",
    "dataset = DatasetDict({\n",
    "    \"train\": Dataset.from_dict(train_set),\n",
    "    \"validation\": Dataset.from_dict(eval_set),\n",
    "    \"test\": Dataset.from_dict(test_set)\n",
    "})\n",
    "\n",
    "dataset.save_to_disk('data/emailsum/emailsum_short')\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/samsum/omission.save train:\n",
      "number: 14732\n",
      "Avg. turns: 11.17\n",
      "Avg. dialog length: 124.08\n",
      "Avg. turn length: 11.11\n",
      "Avg. summary length: 23.44\n",
      "Max turns: 46\n",
      "Max dialog length: 995\n",
      "Max summary length: 73\n",
      "All/bartL/bartB/t5B/t5S/baseline/pegasus: 147320/25424/12687/29473/32959/46777/0\n",
      "All/bartL/bartB/t5B/t5S/baseline/pegasus: 82.58/74.12/76.48/72.57/84.17/94.01/0.00\n",
      "All/bartL/bartB/t5B/t5S/baseline/pegasus: 15.93/11.82/14.17/11.99/16.00/21.59/0.00\n",
      "\n",
      "All/bartL/bartB/t5B/t5S/baseline/pegasus: 34.55/25.33/30.38/26.00/35.03/47.04/0.00\n",
      "\n",
      "data/samsum/omission.save validation:\n",
      "number: 818\n",
      "Avg. turns: 10.83\n",
      "Avg. dialog length: 121.17\n",
      "Avg. turn length: 11.19\n",
      "Avg. summary length: 23.42\n",
      "Max turns: 30\n",
      "Max dialog length: 663\n",
      "Max summary length: 68\n",
      "All/bartL/bartB/t5B/t5S/baseline/pegasus: 9816/1636/1636/1636/1636/1636/1636\n",
      "All/bartL/bartB/t5B/t5S/baseline/pegasus: 79.80/69.99/77.38/74.21/85.02/94.80/77.38\n",
      "All/bartL/bartB/t5B/t5S/baseline/pegasus: 15.85/12.15/14.93/13.73/17.43/22.14/14.72\n",
      "\n",
      "All/bartL/bartB/t5B/t5S/baseline/pegasus: 33.89/25.98/31.91/29.36/37.27/47.33/31.48\n",
      "\n",
      "data/samsum/omission.save test:\n",
      "number: 819\n",
      "Avg. turns: 11.25\n",
      "Avg. dialog length: 126.63\n",
      "Avg. turn length: 11.26\n",
      "Avg. summary length: 23.12\n",
      "Max turns: 30\n",
      "Max dialog length: 644\n",
      "Max summary length: 71\n",
      "All/bartL/bartB/t5B/t5S/baseline/pegasus: 9828/1638/1638/1638/1638/1638/1638\n",
      "All/bartL/bartB/t5B/t5S/baseline/pegasus: 81.89/71.79/81.99/78.57/85.71/94.08/79.18\n",
      "All/bartL/bartB/t5B/t5S/baseline/pegasus: 15.45/12.05/15.07/13.57/16.64/21.08/14.31\n",
      "\n",
      "All/bartL/bartB/t5B/t5S/baseline/pegasus: 34.27/26.72/33.41/30.10/36.90/46.75/31.73\n",
      "\n",
      "data/dialsumm/omission.save train:\n",
      "number: 12460\n",
      "Avg. turns: 9.49\n",
      "Avg. dialog length: 187.49\n",
      "Avg. turn length: 19.75\n",
      "Avg. summary length: 31.02\n",
      "Max turns: 61\n",
      "Max dialog length: 1356\n",
      "Max summary length: 212\n",
      "All/bartL/bartB/t5B/t5S/baseline/pegasus: 124600/20766/10132/26897/37056/29749/0\n",
      "All/bartL/bartB/t5B/t5S/baseline/pegasus: 89.17/85.36/86.16/87.12/88.79/95.17/0.00\n",
      "All/bartL/bartB/t5B/t5S/baseline/pegasus: 20.38/17.09/18.71/18.18/20.88/24.81/0.00\n",
      "\n",
      "All/bartL/bartB/t5B/t5S/baseline/pegasus: 34.17/28.51/31.40/30.24/34.95/42.10/0.00\n",
      "\n",
      "data/dialsumm/omission.save validation:\n",
      "number: 500\n",
      "Avg. turns: 9.38\n",
      "Avg. dialog length: 184.98\n",
      "Avg. turn length: 19.72\n",
      "Avg. summary length: 28.96\n",
      "Max turns: 29\n",
      "Max dialog length: 643\n",
      "Max summary length: 89\n",
      "All/bartL/bartB/t5B/t5S/baseline/pegasus: 6000/1000/1000/1000/1000/1000/1000\n",
      "All/bartL/bartB/t5B/t5S/baseline/pegasus: 87.00/82.30/86.20/86.70/88.30/93.60/84.90\n",
      "All/bartL/bartB/t5B/t5S/baseline/pegasus: 18.75/15.87/18.03/17.64/19.89/23.13/17.90\n",
      "\n",
      "All/bartL/bartB/t5B/t5S/baseline/pegasus: 31.92/27.03/30.70/30.05/33.88/39.40/30.48\n",
      "\n",
      "data/dialsumm/omission.save test:\n",
      "number: 500\n",
      "Avg. turns: 9.71\n",
      "Avg. dialog length: 192.50\n",
      "Avg. turn length: 19.83\n",
      "Avg. summary length: 28.42\n",
      "Max turns: 65\n",
      "Max dialog length: 1193\n",
      "Max summary length: 96\n",
      "All/bartL/bartB/t5B/t5S/baseline/pegasus: 6000/1000/1000/1000/1000/1000/1000\n",
      "All/bartL/bartB/t5B/t5S/baseline/pegasus: 85.38/82.40/84.00/83.20/86.10/93.50/83.10\n",
      "All/bartL/bartB/t5B/t5S/baseline/pegasus: 18.32/15.69/17.54/16.95/19.11/23.39/17.27\n",
      "\n",
      "All/bartL/bartB/t5B/t5S/baseline/pegasus: 32.06/27.45/30.68/29.65/33.44/40.92/30.21\n",
      "\n",
      "data/qmsum/omission.save train:\n",
      "number: 1095\n",
      "Avg. turns: 52.60\n",
      "Avg. dialog length: 1137.35\n",
      "Avg. turn length: 21.62\n",
      "Avg. summary length: 71.21\n",
      "Max turns: 581\n",
      "Max dialog length: 9225\n",
      "Max summary length: 233\n",
      "All/bartL/bartB/t5B/t5S/baseline/pegasus: 10950/2973/624/2197/2617/2539/0\n",
      "All/bartL/bartB/t5B/t5S/baseline/pegasus: 98.50/98.79/98.24/97.72/97.82/99.61/0.00\n",
      "All/bartL/bartB/t5B/t5S/baseline/pegasus: 7.96/7.70/7.19/6.88/7.90/9.93/0.00\n",
      "\n",
      "All/bartL/bartB/t5B/t5S/baseline/pegasus: 39.06/37.16/38.66/37.10/38.21/44.56/0.00\n",
      "\n",
      "data/qmsum/omission.save validation:\n",
      "number: 237\n",
      "Avg. turns: 57.72\n",
      "Avg. dialog length: 1145.37\n",
      "Avg. turn length: 19.84\n",
      "Avg. summary length: 71.40\n",
      "Max turns: 461\n",
      "Max dialog length: 6554\n",
      "Max summary length: 178\n",
      "All/bartL/bartB/t5B/t5S/baseline/pegasus: 2844/474/474/474/474/474/474\n",
      "All/bartL/bartB/t5B/t5S/baseline/pegasus: 98.70/97.47/98.95/97.89/98.73/100.00/99.16\n",
      "All/bartL/bartB/t5B/t5S/baseline/pegasus: 7.47/7.02/7.35/7.30/7.53/8.13/7.47\n",
      "\n",
      "All/bartL/bartB/t5B/t5S/baseline/pegasus: 39.95/37.58/39.34/39.05/40.26/43.49/39.97\n",
      "\n",
      "data/qmsum/omission.save test:\n",
      "number: 244\n",
      "Avg. turns: 55.60\n",
      "Avg. dialog length: 1152.22\n",
      "Avg. turn length: 20.72\n",
      "Avg. summary length: 63.86\n",
      "Max turns: 469\n",
      "Max dialog length: 9006\n",
      "Max summary length: 160\n",
      "All/bartL/bartB/t5B/t5S/baseline/pegasus: 2928/488/488/488/488/488/488\n",
      "All/bartL/bartB/t5B/t5S/baseline/pegasus: 98.22/96.72/98.36/97.34/98.36/100.00/98.57\n",
      "All/bartL/bartB/t5B/t5S/baseline/pegasus: 7.58/7.16/7.45/7.43/7.56/8.25/7.66\n",
      "\n",
      "All/bartL/bartB/t5B/t5S/baseline/pegasus: 39.77/37.57/39.04/38.94/39.62/43.27/40.14\n",
      "\n",
      "data/tweetsumm/omission.save train:\n",
      "number: 879\n",
      "Avg. turns: 10.50\n",
      "Avg. dialog length: 243.98\n",
      "Avg. turn length: 23.23\n",
      "Avg. summary length: 48.16\n",
      "Max turns: 25\n",
      "Max dialog length: 716\n",
      "Max summary length: 113\n",
      "All/bartL/bartB/t5B/t5S/baseline/pegasus: 8790/678/649/919/3901/2643/0\n",
      "All/bartL/bartB/t5B/t5S/baseline/pegasus: 97.70/94.25/94.76/94.99/97.90/99.96/0.00\n",
      "All/bartL/bartB/t5B/t5S/baseline/pegasus: 24.66/19.87/21.21/20.90/22.41/31.79/0.00\n",
      "\n",
      "All/bartL/bartB/t5B/t5S/baseline/pegasus: 39.52/31.72/32.48/33.20/36.30/50.88/0.00\n",
      "\n",
      "data/tweetsumm/omission.save validation:\n",
      "number: 110\n",
      "Avg. turns: 10.17\n",
      "Avg. dialog length: 226.05\n",
      "Avg. turn length: 22.22\n",
      "Avg. summary length: 48.41\n",
      "Max turns: 19\n",
      "Max dialog length: 453\n",
      "Max summary length: 86\n",
      "All/bartL/bartB/t5B/t5S/baseline/pegasus: 1320/220/220/220/220/220/220\n",
      "All/bartL/bartB/t5B/t5S/baseline/pegasus: 97.42/96.36/96.82/97.27/98.18/100.00/95.91\n",
      "All/bartL/bartB/t5B/t5S/baseline/pegasus: 24.33/22.12/22.34/22.43/23.99/32.44/22.65\n",
      "\n",
      "All/bartL/bartB/t5B/t5S/baseline/pegasus: 38.73/35.21/35.56/35.70/38.19/51.64/36.06\n",
      "\n",
      "data/tweetsumm/omission.save test:\n",
      "number: 110\n",
      "Avg. turns: 10.64\n",
      "Avg. dialog length: 258.16\n",
      "Avg. turn length: 24.27\n",
      "Avg. summary length: 47.75\n",
      "Max turns: 20\n",
      "Max dialog length: 597\n",
      "Max summary length: 88\n",
      "All/bartL/bartB/t5B/t5S/baseline/pegasus: 1320/220/220/220/220/220/220\n",
      "All/bartL/bartB/t5B/t5S/baseline/pegasus: 97.12/95.00/98.18/95.00/97.27/100.00/97.27\n",
      "All/bartL/bartB/t5B/t5S/baseline/pegasus: 22.89/20.56/21.28/20.85/22.56/30.64/21.45\n",
      "\n",
      "All/bartL/bartB/t5B/t5S/baseline/pegasus: 36.64/32.90/34.06/33.38/36.11/49.04/34.34\n",
      "\n",
      "data/emailsum_long/omission.save train:\n",
      "number: 1800\n",
      "Avg. turns: 6.50\n",
      "Avg. dialog length: 231.29\n",
      "Avg. turn length: 35.58\n",
      "Avg. summary length: 68.48\n",
      "Max turns: 12\n",
      "Max dialog length: 917\n",
      "Max summary length: 118\n",
      "All/bartL/bartB/t5B/t5S/baseline/pegasus: 18000/4735/1243/1800/2243/7979/0\n",
      "All/bartL/bartB/t5B/t5S/baseline/pegasus: 96.95/94.00/94.69/92.83/97.01/99.96/0.00\n",
      "All/bartL/bartB/t5B/t5S/baseline/pegasus: 40.10/30.00/32.84/31.74/37.26/51.09/0.00\n",
      "\n",
      "All/bartL/bartB/t5B/t5S/baseline/pegasus: 57.28/42.31/46.51/45.47/54.24/73.29/0.00\n",
      "\n",
      "data/emailsum_long/omission.save validation:\n",
      "number: 249\n",
      "Avg. turns: 6.46\n",
      "Avg. dialog length: 227.16\n",
      "Avg. turn length: 35.18\n",
      "Avg. summary length: 67.49\n",
      "Max turns: 12\n",
      "Max dialog length: 670\n",
      "Max summary length: 117\n",
      "All/bartL/bartB/t5B/t5S/baseline/pegasus: 2988/498/498/498/498/498/498\n",
      "All/bartL/bartB/t5B/t5S/baseline/pegasus: 96.29/93.17/96.79/94.18/97.19/100.00/96.39\n",
      "All/bartL/bartB/t5B/t5S/baseline/pegasus: 36.43/30.72/33.40/31.31/37.81/50.28/35.07\n",
      "\n",
      "All/bartL/bartB/t5B/t5S/baseline/pegasus: 52.07/43.91/47.73/44.76/54.04/71.87/50.13\n",
      "\n",
      "data/emailsum_long/omission.save test:\n",
      "number: 500\n",
      "Avg. turns: 6.52\n",
      "Avg. dialog length: 243.01\n",
      "Avg. turn length: 37.26\n",
      "Avg. summary length: 69.30\n",
      "Max turns: 12\n",
      "Max dialog length: 779\n",
      "Max summary length: 114\n",
      "All/bartL/bartB/t5B/t5S/baseline/pegasus: 6000/1000/1000/1000/1000/1000/1000\n",
      "All/bartL/bartB/t5B/t5S/baseline/pegasus: 96.88/95.20/95.90/95.30/97.90/99.90/97.10\n",
      "All/bartL/bartB/t5B/t5S/baseline/pegasus: 37.53/32.98/35.28/33.30/38.73/49.06/35.83\n",
      "\n",
      "All/bartL/bartB/t5B/t5S/baseline/pegasus: 53.26/46.80/50.07/47.26/54.96/69.63/50.85\n",
      "\n",
      "data/emailsum_short/omission.save train:\n",
      "number: 1800\n",
      "Avg. turns: 6.50\n",
      "Avg. dialog length: 231.29\n",
      "Avg. turn length: 35.58\n",
      "Avg. summary length: 26.87\n",
      "Max turns: 12\n",
      "Max dialog length: 917\n",
      "Max summary length: 38\n",
      "All/bartL/bartB/t5B/t5S/baseline/pegasus: 18000/2581/730/3939/3203/7547/0\n",
      "All/bartL/bartB/t5B/t5S/baseline/pegasus: 92.18/88.69/88.36/83.24/90.17/99.27/0.00\n",
      "All/bartL/bartB/t5B/t5S/baseline/pegasus: 26.34/20.60/23.41/19.36/23.98/34.10/0.00\n",
      "\n",
      "All/bartL/bartB/t5B/t5S/baseline/pegasus: 47.73/38.32/42.00/35.71/43.25/60.68/0.00\n",
      "\n",
      "data/emailsum_short/omission.save validation:\n",
      "number: 249\n",
      "Avg. turns: 6.46\n",
      "Avg. dialog length: 227.16\n",
      "Avg. turn length: 35.18\n",
      "Avg. summary length: 26.24\n",
      "Max turns: 12\n",
      "Max dialog length: 670\n",
      "Max summary length: 37\n",
      "All/bartL/bartB/t5B/t5S/baseline/pegasus: 2988/498/498/498/498/498/498\n",
      "All/bartL/bartB/t5B/t5S/baseline/pegasus: 89.06/85.74/88.76/82.73/91.57/99.20/86.35\n",
      "All/bartL/bartB/t5B/t5S/baseline/pegasus: 25.59/22.48/24.91/21.46/26.24/34.11/24.32\n",
      "\n",
      "All/bartL/bartB/t5B/t5S/baseline/pegasus: 45.56/40.03/44.35/38.21/46.73/60.74/43.30\n",
      "\n",
      "data/emailsum_short/omission.save test:\n",
      "number: 500\n",
      "Avg. turns: 6.52\n",
      "Avg. dialog length: 243.01\n",
      "Avg. turn length: 37.26\n",
      "Avg. summary length: 28.18\n",
      "Max turns: 12\n",
      "Max dialog length: 779\n",
      "Max summary length: 42\n",
      "All/bartL/bartB/t5B/t5S/baseline/pegasus: 6000/1000/1000/1000/1000/1000/1000\n",
      "All/bartL/bartB/t5B/t5S/baseline/pegasus: 90.58/86.70/88.40/88.20/90.80/98.20/91.20\n",
      "All/bartL/bartB/t5B/t5S/baseline/pegasus: 24.85/22.26/23.89/21.74/24.89/32.55/23.77\n",
      "\n",
      "All/bartL/bartB/t5B/t5S/baseline/pegasus: 43.22/38.72/41.55/37.81/43.28/56.61/41.33\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from pandas import ExcelWriter\n",
    "\n",
    "datalist = ['data/samsum/omission.save',\n",
    "            'data/dialsumm/omission.save',\n",
    "            'data/qmsum/omission.save',\n",
    "            'data/tweetsumm/omission.save',\n",
    "            'data/emailsum_long/omission.save',\n",
    "            'data/emailsum_short/omission.save'\n",
    "            ]\n",
    "# datalist = ['data/emailsum/emailsum_short', 'data/emailsum/emailsum_long']\n",
    "output_excel = ExcelWriter(\"data_statistics.xlsx\")\n",
    "\n",
    "results = []\n",
    "for data_path in datalist:\n",
    "    dataset = load_from_disk(data_path)\n",
    "    for split in ['train', 'validation', 'test']:\n",
    "        num = len(dataset[split])\n",
    "        turns = 0\n",
    "        tokens = 0\n",
    "        summary_tokens = 0\n",
    "        max_turns = 0\n",
    "        max_tokens = 0\n",
    "        max_summary_tokens = 0\n",
    "        nAll = 0\n",
    "        nbartL = 0\n",
    "        nbartB = 0\n",
    "        nt5B = 0\n",
    "        nt5S = 0\n",
    "        nbaseline = 0\n",
    "        npegasus = 0\n",
    "        omitRateAll = 0\n",
    "        omitRatebartL = 0\n",
    "        omitRatebartB = 0\n",
    "        omitRatet5B = 0.\n",
    "        omitRatet5S = 0\n",
    "        omitRatebaseline = 0\n",
    "        omitRatepegasus = 0\n",
    "        turnAll = 0\n",
    "        turnbartL = 0\n",
    "        turnbartB = 0\n",
    "        turnt5B = 0\n",
    "        turnt5S = 0\n",
    "        turnbaseline = 0\n",
    "        turnpegasus = 0\n",
    "        SomitRateAll = 0\n",
    "        SomitRatebartL = 0\n",
    "        SomitRatebartB = 0\n",
    "        SomitRatet5B = 0.\n",
    "        SomitRatet5S = 0\n",
    "        SomitRatebaseline = 0\n",
    "        SomitRatepegasus = 0\n",
    "        oracleAll = 0\n",
    "        oraclebartL = 0\n",
    "        oraclebartB = 0\n",
    "        oraclet5B = 0\n",
    "        oraclet5S = 0\n",
    "        oraclebaseline = 0\n",
    "        oraclepegasus = 0\n",
    "        for ex in dataset[split]:\n",
    "            turn_num = len(ex['dialogue'].replace('\\r\\n', '\\n').split('\\n'))\n",
    "            turns += turn_num\n",
    "            max_turns = max(max_turns, turn_num)\n",
    "            dial = word_tokenize(ex['dialogue'])\n",
    "            summ = word_tokenize(ex['summary'])\n",
    "            tokens += len(dial)\n",
    "            summary_tokens += len(summ)\n",
    "            max_tokens = max(max_tokens, len(dial))\n",
    "            max_summary_tokens = max(max_summary_tokens, len(summ))\n",
    "            labels = ex['omission_labels']\n",
    "            oracles = ex['oracle_labels']\n",
    "            for i, p in enumerate(ex['preds']):\n",
    "                nAll += 1\n",
    "                turnAll += turn_num\n",
    "                oracleAll += len(oracles)\n",
    "                if len(labels[i]) > 0:\n",
    "                    omitRateAll += 1\n",
    "                    SomitRateAll += len(labels[i])\n",
    "                if p['source'] == 'bart_large':\n",
    "                    nbartL += 1\n",
    "                    turnbartL += turn_num\n",
    "                    oraclebartL += len(oracles)\n",
    "                    if len(labels[i]) > 0:\n",
    "                        omitRatebartL += 1\n",
    "                        SomitRatebartL += len(labels[i])\n",
    "                elif p['source'] == 'bart_base':\n",
    "                    nbartB += 1\n",
    "                    turnbartB += turn_num\n",
    "                    oraclebartB += len(oracles)\n",
    "                    if len(labels[i]) > 0:\n",
    "                        omitRatebartB += 1\n",
    "                        SomitRatebartB += len(labels[i])\n",
    "                elif p['source'] == 't5_base':\n",
    "                    nt5B += 1\n",
    "                    turnt5B += turn_num\n",
    "                    oraclet5B += len(oracles)\n",
    "                    if len(labels[i]) > 0:\n",
    "                        omitRatet5B += 1\n",
    "                        SomitRatet5B += len(labels[i])\n",
    "                elif p['source'] == 't5_small':\n",
    "                    nt5S += 1\n",
    "                    turnt5S += turn_num\n",
    "                    oraclet5S += len(oracles)\n",
    "                    if len(labels[i]) > 0:\n",
    "                        omitRatet5S += 1\n",
    "                        SomitRatet5S += len(labels[i])\n",
    "                elif p['source'] == 'baseline':\n",
    "                    nbaseline += 1\n",
    "                    turnbaseline += turn_num\n",
    "                    oraclebaseline += len(oracles)\n",
    "                    if len(labels[i]) > 0:\n",
    "                        omitRatebaseline += 1\n",
    "                        SomitRatebaseline += len(labels[i])\n",
    "                else:\n",
    "                    npegasus += 1\n",
    "                    turnpegasus += turn_num\n",
    "                    oraclepegasus += len(oracles)\n",
    "                    if len(labels[i]) > 0:\n",
    "                        omitRatepegasus += 1\n",
    "                        SomitRatepegasus += len(labels[i])\n",
    "\n",
    "        print(\"%s %s:\\nnumber: %d\\nAvg. turns: %.2f\\nAvg. dialog length: %.2f\\nAvg. turn length: %.2f\\nAvg. summary length: %.2f\" %\n",
    "            (data_path, split, num, turns / num, tokens / num, tokens / turns, summary_tokens / num))\n",
    "        print(\"Max turns: %d\\nMax dialog length: %d\\nMax summary length: %d\" %\n",
    "            (max_turns, max_tokens, max_summary_tokens))\n",
    "        print(\"All/bartL/bartB/t5B/t5S/baseline/pegasus: %d/%d/%d/%d/%d/%d/%d\" %\n",
    "            (nAll, nbartL, nbartB, nt5B, nt5S, nbaseline, npegasus))\n",
    "        print(\"All/bartL/bartB/t5B/t5S/baseline/pegasus: %.2f/%.2f/%.2f/%.2f/%.2f/%.2f/%.2f\" %\n",
    "            (omitRateAll / (nAll+1e-8) * 100,\n",
    "             omitRatebartL / (nbartL+1e-8) * 100,\n",
    "             omitRatebartB / (nbartB+1e-8) * 100,\n",
    "             omitRatet5B / (nt5B+1e-8) * 100,\n",
    "             omitRatet5S / (nt5S+1e-8) * 100,\n",
    "             omitRatebaseline / (nbaseline+1e-8) * 100,\n",
    "             omitRatepegasus / (npegasus+1e-8) * 100))\n",
    "        print(\"All/bartL/bartB/t5B/t5S/baseline/pegasus: %.2f/%.2f/%.2f/%.2f/%.2f/%.2f/%.2f\\n\" %\n",
    "            (SomitRateAll / (turnAll+1e-8) * 100,\n",
    "             SomitRatebartL / (turnbartL+1e-8) * 100,\n",
    "             SomitRatebartB / (turnbartB+1e-8) * 100,\n",
    "             SomitRatet5B / (turnt5B+1e-8) * 100,\n",
    "             SomitRatet5S / (turnt5S+1e-8) * 100,\n",
    "             SomitRatebaseline / (turnbaseline+1e-8) * 100,\n",
    "             SomitRatepegasus / (turnpegasus+1e-8) * 100))\n",
    "        print(\"All/bartL/bartB/t5B/t5S/baseline/pegasus: %.2f/%.2f/%.2f/%.2f/%.2f/%.2f/%.2f\\n\" %\n",
    "            (SomitRateAll / (oracleAll+1e-8) * 100,\n",
    "             SomitRatebartL / (oraclebartL+1e-8) * 100,\n",
    "             SomitRatebartB / (oraclebartB+1e-8) * 100,\n",
    "             SomitRatet5B / (oraclet5B+1e-8) * 100,\n",
    "             SomitRatet5S / (oraclet5S+1e-8) * 100,\n",
    "             SomitRatebaseline / (oraclebaseline+1e-8) * 100,\n",
    "             SomitRatepegasus / (oraclepegasus+1e-8) * 100))\n",
    "        results.append([data_path.split('/')[1], split, num, turns / num, tokens / num, tokens / turns, summary_tokens / num,\n",
    "                        max_turns, max_tokens, max_summary_tokens, nAll, nbartL, nbartB, nt5B, nt5S, nbaseline, npegasus,\n",
    "                        omitRateAll / (nAll+1e-8) * 100,\n",
    "                        omitRatebartL / (nbartL+1e-8) * 100,\n",
    "                        omitRatebartB / (nbartB+1e-8) * 100,\n",
    "                        omitRatet5B / (nt5B+1e-8) * 100,\n",
    "                        omitRatet5S / (nt5S+1e-8) * 100,\n",
    "                        omitRatebaseline / (nbaseline+1e-8) * 100,\n",
    "                        omitRatepegasus / (npegasus+1e-8) * 100,\n",
    "                        SomitRateAll / (turnAll+1e-8) * 100,\n",
    "                        SomitRatebartL / (turnbartL+1e-8) * 100,\n",
    "                        SomitRatebartB / (turnbartB+1e-8) * 100,\n",
    "                        SomitRatet5B / (turnt5B+1e-8) * 100,\n",
    "                        SomitRatet5S / (turnt5S+1e-8) * 100,\n",
    "                        SomitRatebaseline / (turnbaseline+1e-8) * 100,\n",
    "                        SomitRatepegasus / (turnpegasus+1e-8) * 100,\n",
    "                        SomitRateAll / (oracleAll+1e-8) * 100,\n",
    "                        SomitRatebartL / (oraclebartL+1e-8) * 100,\n",
    "                        SomitRatebartB / (oraclebartB+1e-8) * 100,\n",
    "                        SomitRatet5B / (oraclet5B+1e-8) * 100,\n",
    "                        SomitRatet5S / (oraclet5S+1e-8) * 100,\n",
    "                        SomitRatebaseline / (oraclebaseline+1e-8) * 100,\n",
    "                        SomitRatepegasus / (oraclepegasus+1e-8) * 100])\n",
    "        df = pd.DataFrame(results)\n",
    "df.to_excel(output_excel, \"Sheet1\", index=False)\n",
    "output_excel.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- encoding: utf-8 -*-\n",
    " \n",
    "# 0.0~0.20 (slight), 0.21~0.40 (fair), 0.41~0.60 (moderate)\n",
    "# 0.61~0.80 (substantial), 0.81~1 (almost perfect)\n",
    " \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    " \n",
    "def kappa(testData, k):\n",
    "    dataMat = np.mat(testData)\n",
    "    P0 = 0.0\n",
    "    for i in range(k):\n",
    "        P0 += dataMat[i, i]*1.0\n",
    "    xsum = np.sum(dataMat, axis=1)\n",
    "    ysum = np.sum(dataMat, axis=0)\n",
    "\n",
    "    Pe  = float(ysum*xsum)/k**2\n",
    "    P0 = float(P0/k*1.0)\n",
    "    cohens_coefficient = float((P0-Pe)/(1-Pe))\n",
    "    return cohens_coefficient\n",
    " \n",
    "def fleiss_kappa(testData, N, k, n): # N samples, k classes, n annotators.\n",
    "    dataMat = np.mat(testData, float)\n",
    "    oneMat = np.ones((k, 1))\n",
    "    sum = 0.0\n",
    "    P0 = 0.0\n",
    "    for i in range(N):\n",
    "        temp = 0.0\n",
    "        for j in range(k):\n",
    "            sum += dataMat[i, j]\n",
    "            temp += 1.0*dataMat[i, j]**2\n",
    "        temp -= n\n",
    "        temp /= (n-1)*n\n",
    "        P0 += temp\n",
    "    P0 = 1.0*P0/N\n",
    "    ysum = np.sum(dataMat, axis=0)\n",
    "    for i in range(k):\n",
    "        ysum[0, i] = (ysum[0, i]/sum)**2\n",
    "    Pe = ysum*oneMat*1.0\n",
    "    ans = (P0-Pe)/(1-Pe)\n",
    "    return ans[0, 0]\n",
    " \n",
    " \n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    data = [[0, 0] for _ in range(200)]\n",
    "    # A annotator\n",
    "    excel_a = pd.read_excel('annotation/A/data_dialsumm-A.xlsx')\n",
    "    # Read the values of the file in the dataframe\n",
    "    data_a = pd.DataFrame(excel_a, columns=['Omission Labels', 'Omission Words', 'Accept (Y/N)',\n",
    "                                          'New Omission Labels', 'New Omission Words', 'Omission Error'])\n",
    "    cnt_a = 0\n",
    "    data_a = list(zip(*[data_a[key] for key in data_a.keys()]))\n",
    "    for idx, ex in enumerate(data_a):\n",
    "        la, w, acc, new_la, new_w, err = ex\n",
    "        if acc == 'Y':\n",
    "            cnt_a += 1\n",
    "            data[idx][1] += 1\n",
    "        elif la == new_la:\n",
    "            cnt_a += 1\n",
    "            data[idx][1] += 1\n",
    "        else:\n",
    "            data[idx][0] += 1\n",
    "    print(cnt_a)\n",
    "\n",
    "    # B annotator\n",
    "    excel_b = pd.read_excel('annotation/B/data_dialsumm-B.xlsx')\n",
    "    # Read the values of the file in the dataframe\n",
    "    data_b = pd.DataFrame(excel_b, columns=['Omission Labels', 'Omission Words', 'Accept (Y/N)',\n",
    "                                          'New Omission Labels', 'New Omission Words', 'Omission Error'])\n",
    "    cnt_b = 0\n",
    "    data_b = list(zip(*[data_b[key] for key in data_b.keys()]))\n",
    "    for idx, ex in enumerate(data_b):\n",
    "        la, w, acc, new_la, new_w, err = ex\n",
    "        if acc == 'Y':\n",
    "            cnt_b += 1\n",
    "            data[idx][1] += 1\n",
    "        elif la == new_la:\n",
    "            cnt_b += 1\n",
    "            data[idx][1] += 1\n",
    "        else:\n",
    "            data[idx][0] += 1\n",
    "    print(cnt_b)\n",
    "\n",
    "    # C annotator\n",
    "    excel_c = pd.read_excel('annotation/C/data_dialsumm-C.xlsx')\n",
    "    # Read the values of the file in the dataframe\n",
    "    data_c = pd.DataFrame(excel_c, columns=['Omission Labels', 'Omission Words', 'Accept (Y/N)',\n",
    "                                          'New Omission Labels', 'New Omission Words', 'Omission Error'])\n",
    "    cnt_c = 0\n",
    "    data_c = list(zip(*[data_c[key] for key in data_c.keys()]))\n",
    "    for idx, ex in enumerate(data_c):\n",
    "        la, w, acc, new_la, new_w, err = ex\n",
    "        if acc == 'Y':\n",
    "            cnt_c += 1\n",
    "            data[idx][1] += 1\n",
    "        elif la == new_la:\n",
    "            cnt_c += 1\n",
    "            data[idx][1] += 1\n",
    "        else:\n",
    "            data[idx][0] += 1\n",
    "    print(cnt_c)\n",
    "    print(\"%.4f, %.4f%%\" % ((cnt_a + cnt_b + cnt_c) / 3., (cnt_a + cnt_b + cnt_c) / (200 * 3.) * 100))\n",
    "\n",
    "    res = fleiss_kappa(data, 200, 2, 3)\n",
    "    print(res)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oracle omission distributions\n",
    "import json\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from datasets import load_from_disk\n",
    "from pandas import ExcelWriter\n",
    "\n",
    "dataset = load_from_disk(\"data/tweetsumm/omission.save\")\n",
    "output_excel = ExcelWriter(\"test_results.xlsx\")\n",
    "results = []\n",
    "\n",
    "# uttrnum = defaultdict(int)\n",
    "# oraclenum = defaultdict(int)\n",
    "# omitnum = defaultdict(int)\n",
    "# for ex in dataset['test']:\n",
    "#     cand_num = len(ex['preds'])\n",
    "#     turn_num = len(ex['dialogue'].replace('\\r\\n', '\\n').split('\\n'))\n",
    "#     for idx in range(turn_num):\n",
    "#         uttrnum[idx] += cand_num\n",
    "#     for item in ex['oracle_labels']:\n",
    "#         oraclenum[item] += cand_num\n",
    "#     for la in ex['omission_labels']:\n",
    "#         for item in la:\n",
    "#             omitnum[item] += 1\n",
    "\n",
    "# uttrnum = sorted(uttrnum.items(), key=lambda x: x[0])\n",
    "# oraclenum = sorted(oraclenum.items(), key=lambda x: x[0])\n",
    "# omitnum = sorted(omitnum.items(), key=lambda x: x[0])\n",
    "\n",
    "for ex in dataset['test']:\n",
    "    turn_num = len(ex['dialogue'].replace('\\r\\n', '\\n').split('\\n'))\n",
    "    turn_class = min((turn_num-1) // 2 + 1, 10)\n",
    "    for la in ex['omission_labels']:\n",
    "        for item in la:\n",
    "            results.append([turn_class, item / (turn_num-1)])\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df.to_excel(output_excel, \"Sheet1\", index=False)\n",
    "output_excel.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Candidate Summary Evaluation\n",
    "import json\n",
    "import nltk\n",
    "from statistics import mean\n",
    "from src.others.metric import Metric\n",
    "from datasets import load_from_disk, load_metric\n",
    "from pandas import ExcelWriter\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [label.strip() for label in labels]\n",
    "\n",
    "    # rougeLSum expects newline after each sentence\n",
    "    preds = [\"\".join(nltk.sent_tokenize(pred)) for pred in preds]\n",
    "    labels = [\"\".join(nltk.sent_tokenize(label)) for label in labels]\n",
    "\n",
    "    return preds, labels\n",
    "\n",
    "def word_tokenize(preds, labels):\n",
    "    preds = [nltk.word_tokenize(pred) for pred in preds]\n",
    "    labels = [nltk.word_tokenize(label) for label in labels]\n",
    "    return preds, labels\n",
    "\n",
    "stop_word_set = set()\n",
    "with open('src/others/stop_word_list', 'r') as f:\n",
    "    for word in f:\n",
    "        stop_word_set.add(word.strip())\n",
    "\n",
    "dataset = load_from_disk(\"data/qmsum/omission.save\")\n",
    "\n",
    "metric = Metric()\n",
    "refs = []\n",
    "cands = []\n",
    "\n",
    "omit_rates = []\n",
    "for ex in dataset['test']:\n",
    "    turns = ex['dialogue'].replace('\\r\\n', '\\n').split('\\n')\n",
    "    oracle_word = set([w for w in nltk.word_tokenize(ex['summary'].lower()) if w not in stop_word_set])\n",
    "    oracle_texts = \" \".join([turns[idx].lower() for idx in ex['oracle_labels']])\n",
    "    oracle_num = len(set([w for w in nltk.word_tokenize(oracle_texts) if w in oracle_word]))\n",
    "    ref = ex['summary']\n",
    "    for i, p in enumerate(ex['preds']):\n",
    "        if p['source'] != 'pegasus':\n",
    "            continue\n",
    "        cand = p['pred']\n",
    "        omit_rates.append(len(sum(ex['omission_words'][i], [])) / (oracle_num+1e-8))\n",
    "        refs.append(ref)\n",
    "        cands.append(cand)\n",
    "\n",
    "print(\"Total pairs: %d\" % len(refs))\n",
    "print(\"Avg omit rate %.4f\" % mean(omit_rates))\n",
    "\n",
    "cands, refs = postprocess_text(cands, refs)\n",
    "\n",
    "tokenized_cands, tokenized_refs = word_tokenize(cands, refs)\n",
    "\n",
    "# compute bleu\n",
    "bleu_score = metric.bleu._compute(tokenized_cands, [[ref] for ref in tokenized_refs])\n",
    "bleu_score = {'bleu': round(bleu_score['bleu'] * 100, 2)}\n",
    "\n",
    "# compute rouge\n",
    "metric.rouge.add_batch(predictions=cands, references=refs)\n",
    "rouge_score = metric.rouge.compute(use_stemmer=True)\n",
    "rouge_score = {key: value.mid.fmeasure * 100 for key, value in rouge_score.items()}\n",
    "rouge_score = {k: round(v, 2) for k, v in rouge_score.items()}\n",
    "\n",
    "# compute bertscore roberta-base\n",
    "metric.bertscore.add_batch(predictions=cands, references=refs)\n",
    "bert_score_base = metric.bertscore.compute(model_type='roberta-base')\n",
    "bert_score_base = {'precision': round(mean(bert_score_base['precision']) * 100, 2),\n",
    "                   'recall': round(mean(bert_score_base['recall']) * 100, 2),\n",
    "                   'f1': round(mean(bert_score_base['f1']) * 100, 2)}\n",
    "\n",
    "# compute bertscore roberta-large\n",
    "metric.bertscore.add_batch(predictions=cands, references=refs)\n",
    "bert_score_large = metric.bertscore.compute(model_type='roberta-large')\n",
    "bert_score_large = {'precision': round(mean(bert_score_large['precision']) * 100, 2),\n",
    "                    'recall': round(mean(bert_score_large['recall']) * 100, 2),\n",
    "                    'f1': round(mean(bert_score_large['f1']) * 100, 2)}\n",
    "\n",
    "# compute bleurt score\n",
    "bleurt_metric = load_metric('bleurt', \"BLEURT-20\", keep_in_memory=True)\n",
    "bleurt_score = bleurt_metric._compute(cands, refs)\n",
    "bleurt_score = {'score': round(mean(bleurt_score['scores']) * 100, 2)}\n",
    "\n",
    "print({\n",
    "    'rouge': rouge_score,\n",
    "    'bleu': bleu_score,\n",
    "    'bertscore_base': bert_score_base,\n",
    "    'bertscore_large': bert_score_large,\n",
    "    'bleurt': bleurt_score\n",
    "})\n",
    "print(mean(omit_rates)* 100)\n",
    "print(rouge_score['rouge1'])\n",
    "print(rouge_score['rouge2'])\n",
    "print(rouge_score['rougeLsum'])\n",
    "print(bleu_score['bleu'])\n",
    "print(bert_score_base['f1'])\n",
    "print(bert_score_large['f1'])\n",
    "print(bleurt_score['score'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0ca2e0c13133e8cf190c7e9bf6798c5e4739fe6adb22798f1d3036fe0cf0aad6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
